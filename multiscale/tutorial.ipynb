{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multiscale Clustering of Molecular Localizations Using MIRO**\n",
    "\n",
    "This tutorial demonstrates how to train and apply **MIRO** for multiscale clustering of spatial point clouds from single-molecule localization microscopy (SMLM), focusing on nuclear pore complex datasets.\n",
    "\n",
    "We show how to train **MIRO** using simulated data and then evaluate its performance on experimental SMLM datasets. In addition, the tutorial covers how to build custom data loaders tailored to the structure and format of each dataset, an essential step for applying MIRO to diverse real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure the library path is in sys.path\n",
    "lib_path = Path.cwd().parent.resolve()\n",
    "\n",
    "if str(lib_path) not in sys.path:\n",
    "    sys.path.insert(0, str(lib_path))\n",
    "\n",
    "import lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Load the Data**\n",
    "\n",
    "To begin, load the training dataset.\n",
    "\n",
    "It consists of pre-generated synthetic images, each containing between 5 and 9 nuclear pore-like structures. Each structure is composed of 8 Gaussian clusters arranged symmetrically around a shared central vertex, mimicking the characteristic geometry of nuclear pore complexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_data = pd.read_csv(\"data/training_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Build the training dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the training dataset by converting each synthetic image into a graph-based representation compatible with **MIRO**. The code snippet below demonstrates how to build a custom data loader tailored to this multiscale setting.\n",
    "\n",
    "The `MultiscaleGraphDataset` class reads each training image, computes the ground truth displacement vectors for each scale (in this case, two: the outer *ring* structure and the inner *Gaussian* cores), and constructs a graph based on spatial connectivity. Nodes in the graph represent individual molecular localizations, while edges are defined using Delaunay triangulation and filtered by a connectivity radius.\n",
    "\n",
    "For each image (field of view), the loader returns a `torch_geometric.data.Data` object, storing the graph structure, positional features, and scale-specific ground truth displacements. These data objects form the input to the MIRO model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.tri as tri\n",
    "import itertools\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch_geometric.transforms import AddLaplacianEigenvectorPE\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "class MultiscaleGraphDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        training_images,\n",
    "        connectivity_radius=1,\n",
    "    ):\n",
    "        self.training_images = training_images\n",
    "        self.connectivity_radius = connectivity_radius\n",
    "\n",
    "        self.laplacian_embedding = AddLaplacianEigenvectorPE(\n",
    "            5, attr_name=\"x\", is_undirected=True\n",
    "        )\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.generate_dataset()\n",
    "\n",
    "    def generate_dataset(self):\n",
    "        \"\"\"Generate a dataset of graph-structured data.\"\"\"\n",
    "        dataset = []\n",
    "        for _, df_set in tqdm.tqdm_notebook(\n",
    "            self.training_images.groupby(\"set\", sort=False),\n",
    "            desc=\"Generating dataset\",\n",
    "        ):\n",
    "            positions = df_set[[\"x\", \"y\"]].to_numpy()\n",
    "\n",
    "            cluster_means = self.compute_position_means(df_set, \"label\")\n",
    "            subcluster_means = self.compute_position_means(df_set, \"sublabel\")\n",
    "\n",
    "            deltas = positions - cluster_means\n",
    "            subdeltas = positions - subcluster_means\n",
    "\n",
    "            data = self.create_data_object(positions, subdeltas, deltas)\n",
    "            dataset.append(data)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def compute_position_means(self, df, group_col: str) -> np.ndarray:\n",
    "        return (\n",
    "            df.groupby(group_col)[[\"x\", \"y\"]]\n",
    "            .transform(\"mean\")\n",
    "            .mask(df[group_col].eq(0.0), df[[\"x\", \"y\"]])\n",
    "            .to_numpy()\n",
    "        )\n",
    "\n",
    "    def create_data_object(self, positions, subdeltas, deltas):\n",
    "        \"\"\"Create a `Data` object from positions and deltas.\"\"\"\n",
    "        data = Data()\n",
    "\n",
    "        # Prepare ground truth displacements\n",
    "        data.y_sub, data.y = (\n",
    "            torch.tensor(subdeltas, dtype=torch.float) / self.connectivity_radius,\n",
    "            torch.tensor(deltas, dtype=torch.float) / self.connectivity_radius,\n",
    "        )\n",
    "\n",
    "        # Add graph structure\n",
    "        data.edge_index, data.edge_attr = self.compute_connectivity(positions)\n",
    "        data.num_nodes = positions.shape[0]\n",
    "\n",
    "        # Add positional and embedding features\n",
    "        data = self.laplacian_embedding(data)\n",
    "        data.x = torch.abs(data.x)\n",
    "        data.position = torch.tensor(positions, dtype=torch.float)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def compute_connectivity(self, positions):\n",
    "        \"\"\"Compute the connectivity graph and edge attributes.\"\"\"\n",
    "        delaunay = tri.Triangulation(positions[:, 0], positions[:, 1])\n",
    "        edges = self.extract_edges(delaunay.triangles)\n",
    "\n",
    "        distances, displacements = self.compute_edge_metrics(edges, positions)\n",
    "        valid_mask = distances < self.connectivity_radius\n",
    "\n",
    "        edges = edges[valid_mask]\n",
    "        distances = distances[valid_mask, None]\n",
    "        displacements = displacements[valid_mask]\n",
    "\n",
    "        edges, displacements, distances = self.make_graph_undirected(\n",
    "            edges, displacements, distances\n",
    "        )\n",
    "\n",
    "        edge_index, edge_attr = self.format_edges_and_attributes(\n",
    "            edges, displacements, distances\n",
    "        )\n",
    "        return edge_index, edge_attr\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_edges(triangles):\n",
    "        \"\"\"Extract edges from triangles.\"\"\"\n",
    "        edges = [\n",
    "            np.array(list(itertools.combinations(triangle, r=2)))[[1, 0, 2]]\n",
    "            for triangle in triangles\n",
    "        ]\n",
    "        return np.concatenate(edges, axis=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_edge_metrics(edges, positions):\n",
    "        \"\"\"Compute displacements and distances for edges.\"\"\"\n",
    "        displacements = positions[edges[:, 0]] - positions[edges[:, 1]]\n",
    "        distances = np.linalg.norm(displacements, axis=1)\n",
    "        return distances, displacements\n",
    "\n",
    "    @staticmethod\n",
    "    def make_graph_undirected(edges, displacements, distances):\n",
    "        \"\"\"Ensure the graph is undirected by mirroring edges.\"\"\"\n",
    "        edges = np.concatenate([edges, edges[:, [1, 0]]], axis=0)\n",
    "        displacements = np.concatenate([displacements, -displacements], axis=0)\n",
    "        distances = np.concatenate([distances, distances], axis=0)\n",
    "\n",
    "        # Remove duplicate edges\n",
    "        unique_edges, indices = np.unique(edges, axis=0, return_index=True)\n",
    "        return unique_edges, displacements[indices], distances[indices]\n",
    "\n",
    "    def format_edges_and_attributes(self, edges, displacements, distances):\n",
    "        \"\"\"Format edges and their attributes for PyTorch Geometric.\"\"\"\n",
    "        edge_index = torch.tensor(edges.T, dtype=torch.long)\n",
    "        edge_attr = (\n",
    "            torch.cat(\n",
    "                [\n",
    "                    torch.tensor(displacements, dtype=torch.float),\n",
    "                    torch.tensor(distances, dtype=torch.float),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "            / self.connectivity_radius\n",
    "        )\n",
    "        return edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instantiate the dataset builder and generate the training dataset, using a subset of the training images (`set < 1000`) for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = MultiscaleGraphDataset(\n",
    "    training_data,\n",
    "    connectivity_radius=0.2,\n",
    ")\n",
    "training_dataset = builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s take a closer look at one of the training samples.\n",
    "\n",
    "The colormap in the labeled scatter plot represents the magnitude of the **displacement vectors** from each node to its assigned cluster center, across both spatial scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "def plot_training_data(data, figsize=(15, 5), titles=None):\n",
    "    pos = data[\"position\"]        \n",
    "    edges = data[\"edge_index\"].T  \n",
    "    norms = [                    \n",
    "        None,\n",
    "        np.linalg.norm(data[\"y\"], axis=1),\n",
    "        np.linalg.norm(data[\"y_sub\"], axis=1),\n",
    "    ]\n",
    "\n",
    "    titles = titles or [\n",
    "        \"Input Graph\",\n",
    "        \"Ground Truth (gaussians)\",\n",
    "        \"Ground Truth (rings)\",\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize, constrained_layout=True)\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(titles[i], fontsize=16)\n",
    "\n",
    "        if i == 0:\n",
    "            segments = pos[edges]\n",
    "            lc = LineCollection(segments, colors=\"black\",\n",
    "                                linewidths=0.5, alpha=0.3)\n",
    "            ax.add_collection(lc)\n",
    "            ax.scatter(pos[:, 0], pos[:, 1],\n",
    "                       s=10, c=\"orange\", edgecolors=\"black\", zorder=2)\n",
    "        else:\n",
    "            im = ax.scatter(pos[:, 0], pos[:, 1],\n",
    "                            c=norms[i], s=10)\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "\n",
    "idx = random.randrange(len(training_dataset))\n",
    "fig, axes = plot_training_data(training_dataset[idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Create the model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instantiate **MIRO** using the configuration that matches the training data. \n",
    "\n",
    "The model is initialized with a set of key parameters: the number of output features (in this case, 2 for the predicted *x* and *y* displacements), the connectivity radius used to construct the input graphs (which should match the one used during augmentation), the number of recurrent message-passing iterations to apply on the input graphs (set to 20 by default), and `cutoff_iterations`, which defines how many of those iterations are run at the smaller spatial scale before switching to the larger one.\n",
    "\n",
    "In this example, the total 20 recurrent iterations are split into the first 10 focused on the gaussian-scale structures, and the remaining 10 on the rings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "\n",
    "clusterer = dl.mMIRO(\n",
    "    num_outputs=2,  # Number of output features (e.g., x, y displacements)\n",
    "    connectivity_radius=builder.connectivity_radius,  # Radius for graph connectivity (matches dataset)\n",
    "    num_iterations=20,  # Number of iterations for graph processing\n",
    "    cutoff_iterations=10, # Number of iterations at the smaller scale before switching to the larger one\n",
    ")\n",
    "clusterer = clusterer.create()\n",
    "\n",
    "print(clusterer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Train the model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the data loaders and configure the training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=training_dataset,  # The dataset to be loaded\n",
    "    batch_size=4,  # Number of samples per batch\n",
    "    shuffle=True,  # Shuffle the dataset at every epoch\n",
    ")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = dl.Trainer(max_epochs=30)  # Maximum number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train **MIRO**. \n",
    "\n",
    "Alternatively, you can load a pre-trained model by setting `train_model = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_model = True\n",
    "\n",
    "if train_model:\n",
    "    trainer.fit(\n",
    "        clusterer,  # The MIRO model to be trained\n",
    "        train_loader,  # The DataLoader providing the training data\n",
    "    )\n",
    "else:\n",
    "    clusterer.load_state_dict(torch.load(\"models/checkpoint.pt\"))  # Load pre-trained model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Test the model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training is complete, itâ€™s time to evaluate **MIRO** on experimental data obtained from SMLM imaging of Nup96-nMaple in fixed U2OS cells ([Thevathasan, J.V. et al. *Nat Methods* (2019)](https://www.nature.com/articles/s41592-019-0574-9)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/mMaple_fixed-D2O_190510_16_sml.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying **MIRO** to the validation dataset, we normalize the localization coordinates to ensure that the spatial scale of the structures in the test data matches that of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 2000\n",
    "test_data = test_data.assign(\n",
    "    x=lambda df: df.xnm / scale,\n",
    "    y=lambda df: df.ynm / scale,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(\n",
    "    test_data[\"x\"],\n",
    "    test_data[\"y\"],\n",
    "    s=1,\n",
    "    c=\"black\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the test data has been normalized, we proceed to create the graph representation required by **MIRO**. We use the `compute_test_graph` function and set `norm=False` to avoid re-normalizing the data.\n",
    "\n",
    "Note that this step may take a few minutes, depending on the size of the dataset. Alternatively, a pre-computed graph can be loaded by setting `use_precomputed_graph=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_precomputed_graph = False\n",
    "\n",
    "if use_precomputed_graph:\n",
    "    test_graph = torch.load(\"data/test_graph.pt\")\n",
    "else:\n",
    "    test_graph = lib.compute_test_graph(\n",
    "        test_data,\n",
    "        builder=builder,\n",
    "        norm=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply **MIRO** to the test graph to obtain clustering results at multiple spatial scales.\n",
    "\n",
    "For each scale, we specify the iteration from which to extract node embeddings (`from_iter`), along with the DBSCAN parameters (`eps` and `min_samples`) used to define clusters in the learned representation space.\n",
    "\n",
    "We also provide a `scaling` factor to convert the normalized coordinates back to physical units (nanometers) before clustering.\n",
    "\n",
    "The `clusterer.clustering` method applies **MIRO** to the test graph, transforms the node features through the trained model, and performs DBSCAN clustering on the resulting representation. The resulting cluster labels for each scale are stored in `test_data` under `clustering_gaussians` and `clustering_rings`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer.eval()\n",
    "clusterer.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "metadata = {\n",
    "    \"gaussians\": {\"from_iter\": 9,  \"eps\": 4,  \"min_samples\": 4},\n",
    "    \"rings\":     {\"from_iter\": 19, \"eps\": 30, \"min_samples\": 16},\n",
    "}\n",
    "\n",
    "scaling = np.array([2000, 2000])\n",
    "\n",
    "for scale_name, params in metadata.items():\n",
    "    test_data[f\"clustering_{scale_name}\"] = clusterer.clustering(\n",
    "        test_graph,\n",
    "        scaling=scaling,\n",
    "        **params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can visualize the clustering results produced by **MIRO**. \n",
    "\n",
    "The following code selects a region of interest from the test dataset and plots the cluster assignments for the `gaussians` and `rings` scales side by side. Each point represents a localization, and points belonging to the same cluster are shown in the same randomly assigned color. Background points are shown in gray with reduced opacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (\n",
    "    test_data[\"xnm\"].between(29000, 31000)\n",
    "    & test_data[\"ynm\"].between(51500, 53500)\n",
    ")\n",
    "crop = test_data.loc[mask]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), constrained_layout=True)\n",
    "\n",
    "scales = [\"gaussians\", \"rings\"]\n",
    "\n",
    "for ax, scale in zip(axes, scales):\n",
    "    col = f\"clustering_{scale}\"\n",
    "    groups = crop.groupby(col, sort=False)\n",
    "\n",
    "    for label, group in groups:\n",
    "        if label == -1:\n",
    "            color, alpha = \"gray\", 0.6\n",
    "        else:\n",
    "            color = np.random.rand(3)\n",
    "            alpha = 1.0\n",
    "\n",
    "        ax.scatter(\n",
    "            group[\"xnm\"],\n",
    "            group[\"ynm\"],\n",
    "            s=5,\n",
    "            color=color,\n",
    "            alpha=alpha,\n",
    "            edgecolors=\"none\",\n",
    "        )\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f\"{scale}\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
