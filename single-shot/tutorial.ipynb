{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clustering SMLM Point Clouds from a Single Cluster using MIRO**\n",
    "\n",
    "This tutorial demonstrates how to train and apply **MIRO** for clustering spatial point clouds from single-molecule localization microscopy (SMLM). We focus on the *single-shot training* setting, where the model is trained using just **one annotated cluster**. Specifically, we apply this minimal-data approach to scenarios 6 and 5 from the benchmarking dataset introduced in [Nieves et al., *Nature Methods* (2023)](https://www.nature.com/articles/s41592-022-01750-6), which provides a standardized framework for evaluating clustering methods in SMLM.\n",
    "\n",
    "Although this tutorial centers on these two representative scenarios, the same methodology can be readily extended to other datasets in the benchmark or to custom SMLM data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Load the data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of **MIRO**’s key strengths is its ability to learn from extremely limited data. While it typically generalizes well with just a few dozen representative clusters, it can still achieve reasonable performance when trained on a **single annotated cluster**.\n",
    "\n",
    "To begin, we load the training cluster:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the metadata associated with the dataset\n",
    "with open(\"metadata.json\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "ID = 6\n",
    "metadata = metadata[f\"Ground Truth - Scenario {ID}\"]\n",
    "training_cluster = pd.read_csv(\n",
    "    metadata[\"training_cluster_path\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we visualize the training cluster to better understand its structure and characteristics. \n",
    "\n",
    "This step is essential to verify that the data is suitable for training the **MIRO** model. Since we are using only a single cluster, its selection is especially important. It should be representative of the types of clusters we expect to encounter in the broader SMLM dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(\n",
    "    training_cluster[\"x\"],\n",
    "    training_cluster[\"y\"],\n",
    "    s=40,\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Build the training dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MIRO** employs an augmentation pipeline that transforms the training cluster into a large number of diverse point clouds for training.\n",
    "\n",
    "Each point cloud is generated by applying a series of transformations to randomly selected clusters, including geometric transformations (rotations, reflections), stochastic perturbations (localization dropout or addition), and spatial jitter (small random displacements).  These transformed clusters are then randomly placed within a synthetic FOV to generate the final training samples.\n",
    "\n",
    "Importantly, these augmented point clouds are fitted to a normalized square region spanning from 0 to 1 , and **the training crop must be normalized** accordingly. This ensures that, when inserted into synthetic images during augmentation, the spatial scale of the clusters matches that of the validation data, preserving consistency in cluster size and density.\n",
    "\n",
    "The following code initializes the **MIRO** data builder, which generates the augmented training dataset based on the extracted clusters and a set of metadata parameters. These metadata settings define key aspects of the synthetic dataset, such as the number of generated samples, the range of background noise points, the number of clusters per FOV, and the spatial connectivity radius used to define cluster compactness. \n",
    "\n",
    "You can inspect these settings by printing `metadata[\"builder_kwargs\"]`. Once initialized, calling the builder returns a fully augmented dataset ready for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure the library path is in sys.path\n",
    "lib_path = Path.cwd().parent.resolve()\n",
    "\n",
    "if str(lib_path) not in sys.path:\n",
    "    sys.path.insert(0, str(lib_path))\n",
    "\n",
    "import lib\n",
    "\n",
    "# Initialize the MIRO builder with the training clusters and metadata\n",
    "builder = getattr(lib, metadata[\"builder\"])(\n",
    "    [training_cluster], **metadata[\"builder_kwargs\"]\n",
    ")\n",
    "augmented_dataset = builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a closer look at one of the augmented training images.\n",
    "\n",
    "In **MIRO**, each training sample is represented as a **graph**, where nodes correspond to individual molecular localizations and edges are defined via Delaunay triangulation to capture local spatial relationships. You can use the following code to visualize one of these examples.\n",
    "\n",
    "The colormap in the labeled scatter plot represents the magnitude of the **displacement vectors** from each node to its assigned cluster center. These vectors serve as the ground truth during training, enabling **MIRO** to learn transformations that contract structures toward a common center, effectively modeling the underlying cluster geometry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_data(sample_idx):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    data = augmented_dataset[sample_idx]\n",
    "\n",
    "    # Plot the graph representation\n",
    "    for edge in data[\"edge_index\"].T:\n",
    "        x = [data[\"position\"][edge[0]][0], data[\"position\"][edge[1]][0]]\n",
    "        y = [data[\"position\"][edge[0]][1], data[\"position\"][edge[1]][1]]\n",
    "        ax[0].plot(x, y, color=\"black\", linewidth=0.5, alpha=0.3)\n",
    "    ax[0].scatter(\n",
    "        data[\"position\"][:, 0],\n",
    "        data[\"position\"][:, 1],\n",
    "        s=10,\n",
    "        zorder=2,\n",
    "        c=\"orange\",\n",
    "        edgecolors=\"black\",\n",
    "    )\n",
    "    ax[0].set_xticks([])\n",
    "    ax[0].set_yticks([])\n",
    "    ax[0].set_title(\"Input Graph\", fontsize=10)\n",
    "\n",
    "    # Plot the ground truth displacement vectors\n",
    "    ax[1].scatter(\n",
    "        data[\"position\"][:, 0],\n",
    "        data[\"position\"][:, 1],\n",
    "        c=np.linalg.norm(data[\"y\"], axis=1),\n",
    "        s=10,\n",
    "    )\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_yticks([])\n",
    "    ax[1].set_title(\"Ground Truth\", fontsize=10)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.02)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "random_sample_idx = np.random.randint(0, len(augmented_dataset))\n",
    "plot_training_data(random_sample_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Create the model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instantiate **MIRO** using the configuration that matches the training data. \n",
    "\n",
    "The model is initialized with a set of key parameters: the number of output features (in this case, 2 for the predicted *x* and *y* displacements), the connectivity radius used to construct the input graphs (which should match the one used during augmentation), and the number of recurrent message-passing iterations to apply on the input graphs (set to 20 by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "\n",
    "clusterer = dl.MIRO(\n",
    "    num_outputs=2,  # Number of output features (e.g., x, y displacements)\n",
    "    connectivity_radius=builder.connectivity_radius,  # Radius for graph connectivity (matches dataset)\n",
    "    num_iterations=metadata[\"recurrent_iterations\"],  # Number of iterations for graph processing\n",
    ")\n",
    "clusterer = clusterer.create()\n",
    "\n",
    "print(clusterer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Train the model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the data loaders and configure the training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=augmented_dataset,  # The dataset to be loaded\n",
    "    batch_size=4,  # Number of samples per batch\n",
    "    shuffle=True,  # Shuffle the dataset at every epoch\n",
    ")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = dl.Trainer(max_epochs=30)  # Maximum number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train **MIRO**. \n",
    "\n",
    "Alternatively, you can load a pre-trained model by setting `train_model = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_model = False\n",
    "\n",
    "if train_model:\n",
    "    trainer.fit(\n",
    "        clusterer,  # The MIRO model to be trained\n",
    "        train_loader,  # The DataLoader providing the training data\n",
    "    )\n",
    "else:\n",
    "    clusterer.load_state_dict(torch.load(metadata[\"checkpoint\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Test the model**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training is complete, it’s time to evaluate **MIRO** on the validation dataset.\n",
    "\n",
    "Use the code snippet below to load the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = lib.sdownload(id=ID, local_folder=\"data\", blinking=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reads the validation images and applies the trained model to perform clustering. \n",
    "\n",
    "The `clusterer` object includes a built-in `.clustering()` method, which automates the full inference pipeline. This method applies MIRO to each input graph, transforms the node features into the learned **squeezed representation** (where localizations belonging to the same cluster are pulled toward a common center) and runs DBSCAN on this transformed space to produce the final cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "clusterer.eval()\n",
    "clusterer.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pat = re.compile(r\"\\d+\")\n",
    "DIR = Path(path)\n",
    "csv_files = sorted(DIR.glob(\"*.csv\"), key=lambda f: int(pat.search(f.name).group()))\n",
    "\n",
    "idx = {i - 1 for i in metadata[\"training_indices\"]}\n",
    "validation_paths = [f for j, f in enumerate(csv_files) if j not in idx]\n",
    "\n",
    "vresults = []\n",
    "for i, vpath in enumerate(validation_paths):\n",
    "    vdata = pd.read_csv(vpath).copy()\n",
    "    val_graph = lib.compute_test_graph(vdata, builder)\n",
    "\n",
    "    clusters = clusterer.clustering(\n",
    "        val_graph,  # Input graph representing the validation point cloud\n",
    "        eps=metadata[\"MIRO_DBSCAN_params\"][\n",
    "            \"eps\"\n",
    "        ],  # DBSCAN epsilon parameter for neighborhood radius\n",
    "        min_samples=metadata[\"MIRO_DBSCAN_params\"][\n",
    "            \"min_samples\"\n",
    "        ],  # DBSCAN minimum samples parameter for core points\n",
    "        scaling=vdata[[\"x\", \"y\"]]\n",
    "        .max()\n",
    "        .values,  # Used to convert displacements back to the original coordinate scale\n",
    "    )\n",
    "\n",
    "    dbclusters = DBSCAN(\n",
    "        eps=metadata[\"DBSCAN_params\"][\"eps\"],\n",
    "        min_samples=metadata[\"DBSCAN_params\"][\"min_samples\"],\n",
    "    ).fit_predict(vdata[[\"x\", \"y\"]])\n",
    "\n",
    "    vdata[\"clustering-MIRO\"] = clusters + 1\n",
    "    vdata[\"clustering-DBSCAN\"] = dbclusters + 1\n",
    "    vdata[\"set\"] = i\n",
    "    vresults.append(vdata)\n",
    "\n",
    "vresults = pd.concat(vresults, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now compute the average evaluation metrics across the 47 validation images. These include `ARI_values` and `AMI_values`, along with class-imbalance-aware variants such as `ARI_c_values` and `ARI_dagger_values`. We also report `IoU_values` to assess cluster overlap, as well as cluster-level metrics like `JIc_values`, `RMSRE_N_values`, and `RMSE_centr_values`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = lib.calculate_metrics_for_experiments(vresults)\n",
    "aresults = results.groupby('class_names').mean().reset_index().round(2)\n",
    "\n",
    "aresults = aresults.drop(columns=['experiment'])\n",
    "aresults = aresults.set_index('class_names').transpose()\n",
    "aresults.columns.name = None\n",
    "\n",
    "print(\"Average Results:\")\n",
    "print(aresults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we visualize a randomly selected validation image along with its predicted cluster assignments from DBSCAN, MIRO-enhanced DBSCAN, and the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clustering_results(results):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Titles for each subplot\n",
    "    titles = [\"DBSCAN\", \"MIRO-enhanced\", \"Ground Truth\"]\n",
    "\n",
    "    # Loop through each clustering method and visualize results\n",
    "    for i, c in enumerate([\"clustering-DBSCAN\", \"clustering-MIRO\", \"index\"]):\n",
    "        clustering = results[c].copy()\n",
    "        ax[i].set_xticks([])  # Remove x-axis ticks for a cleaner plot\n",
    "        ax[i].set_yticks([])  # Remove y-axis ticks for a cleaner plot\n",
    "        ax[i].set_title(titles[i], fontsize=10)  # Set title for the subplot\n",
    "\n",
    "        # Iterate through unique cluster labels\n",
    "        for u in np.unique(clustering):\n",
    "            if u == 0:  # Background points (label 0)\n",
    "                ax[i].scatter(\n",
    "                    results[\"x\"][results[c] == u],  # x-coordinates of background points\n",
    "                    results[\"y\"][results[c] == u],  # y-coordinates of background points\n",
    "                    s=4,  # Point size\n",
    "                    c=\"gray\",  # Background color\n",
    "                    alpha=0.5,  # Transparency for background points\n",
    "                )\n",
    "            else:  # Clustered points\n",
    "                ax[i].scatter(\n",
    "                    results[\"x\"][results[c] == u],  # x-coordinates of clustered points\n",
    "                    results[\"y\"][results[c] == u],  # y-coordinates of clustered points\n",
    "                    s=4,  # Point size\n",
    "                    c=np.random.rand(3),  # Random RGB color for each cluster\n",
    "                )\n",
    "    plt.subplots_adjust(wspace=0.02)  # Adjust spacing between subplots\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "validation_image = vresults[\n",
    "    vresults[\"set\"] == np.random.choice(vresults[\"set\"].unique())\n",
    "].copy()\n",
    "plot_clustering_results(validation_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
